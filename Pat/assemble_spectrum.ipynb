{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4b5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1269f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models\n",
    "import pandas as pd\n",
    "import os\n",
    "import spfuncs as spf\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "from astropy.nddata import StdDevUncertainty,InverseVariance\n",
    "from scipy.io import readsav\n",
    "from scipy.stats import chi2\n",
    "from scipy.interpolate import UnivariateSpline,CubicSpline\n",
    "from scipy.optimize import curve_fit\n",
    "from IPython.display import clear_output\n",
    "from astropy.convolution import Gaussian1DKernel, convolve_fft\n",
    "from scipy.stats import binned_statistic\n",
    "from specutils import Spectrum1D,SpectralRegion\n",
    "from specutils.fitting import fit_lines\n",
    "from specutils.manipulation import FluxConservingResampler\n",
    "from specutils.manipulation.model_replace import model_replace,extract_region\n",
    "from specutils.analysis import line_flux\n",
    "from matplotlib.lines import Line2D\n",
    "import dust_extinction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b2091",
   "metadata": {},
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32fec4",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e2f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### CONSTANTS ##############\n",
    "c = 3e18 # A/s\n",
    "c_kms = 3e5 # km/s\n",
    "h = 4.1357e-18 # keV s\n",
    "erg = 1/6.2415e8 # 1 erg = 6.2e8 keV\n",
    "pc2au = 206265 # au/pc\n",
    "####################################\n",
    "\n",
    "# global variable for instrument bits\n",
    "INST_BITS = {'G140L':1,\n",
    "             'G140M':2,\n",
    "             'G230L':4,\n",
    "             'G430L':8,\n",
    "             'X-RAY':16, # Chandra or XMM-Newton\n",
    "             'proxy':32,\n",
    "             'lya':64,\n",
    "             'EUV':128,\n",
    "             'BT-Settl':256,\n",
    "             'APEC':512,\n",
    "             'E230M':1024, #HD 149026\n",
    "             'G130M':2048, #L 678-39\n",
    "             'G160M':4096} #L 678-39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2805ee",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bdd7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a spectrum in the given grating directory. If found, updates given grating dict and returns true\n",
    "# Requires spectrum be named x1d_coadd.fits\n",
    "def look_for_data(star,grating_to_find,grating_dict):\n",
    "    # Search through the directories in the Star directory and try to find the given grating\n",
    "    \n",
    "    print('Searching for',grating_to_find)\n",
    "    try:\n",
    "        for root,dirs,files in os.walk('./%s'%(star)):\n",
    "            if(root == './%s\\\\%s'%(star,grating_to_find)):\n",
    "                print('Found directory: %s'%(root))\n",
    "                # Try to find the coadded spectrum in the grating directory\n",
    "                try:\n",
    "                    with fits.open('%s/x1d_coadd.fits'%(root)) as hdul:\n",
    "                        wave = hdul[1].data['WAVELENGTH']\n",
    "                        flux = hdul[1].data['FLUX']\n",
    "                        err = hdul[1].data['ERROR']\n",
    "                        inst = INST_BITS[grating_to_find]*np.ones(len(wave))\n",
    "                    print('Retrieved',grating_to_find)\n",
    "                    grating_dict[grating_to_find] = np.array([wave,flux,err,inst])\n",
    "                    return True\n",
    "                except:\n",
    "                    print('Error finding spectrum')\n",
    "    except:\n",
    "        print('Error finding star directory')\n",
    "    \n",
    "    print('Did not find directory')\n",
    "    return False\n",
    "\n",
    "# Make an emission line given the line center and integrated line flux\n",
    "def make_emission_line(line_center,flux_to_match):\n",
    "    # INPUT:\n",
    "    # line_center: center of emission line in angstroms]\n",
    "    # flux_to_match: integrated line flux\n",
    "    # OUTPUT:\n",
    "    # spectrum: A 1d spectrum of the created emission line to be insert into the final combined spectrum\n",
    "    # width: width of the emission line in Ã…\n",
    "    # best_amp: The amplitude of the best-fit gaussian model\n",
    "    # int_flux: the integrated flux of the best-fit gaussian model\n",
    "    \n",
    "    \n",
    "    # Creates a new wavelength grid assuming that +/-3A is large enough to cover the entire line (should be /shrug)\n",
    "    new_wave_grid = np.linspace(line_center-1.5,line_center+1.5,num=1000)\n",
    "    \n",
    "    # Converts to velocity space to calculate the FWHM\n",
    "    v_array = (new_wave_grid-line_center)/new_wave_grid*c_kms\n",
    "        \n",
    "    # Set width to 60 or 70 km/s based on spectral type.\n",
    "    # Estimations from France(2020) Barnard * paper & France (2010) HD209458 paper\n",
    "    if(STELLAR_TYPE.lower()=='m'):\n",
    "        width = 60 # km/s    \n",
    "    else:\n",
    "        width = 70 # km/s\n",
    "    \n",
    "    lower_bound,upper_bound = np.where(np.abs(v_array) <= width)[0][0],np.where(np.abs(v_array) <= width)[0][-1]\n",
    "    \n",
    "    # Convert the FWHM back to wavelength space\n",
    "    FWHM_wave = new_wave_grid[upper_bound]-new_wave_grid[lower_bound]\n",
    "    \n",
    "    # Create an array of amplitudes to iterate over\n",
    "    amp_array = np.linspace(flux_to_match*1e-1,flux_to_match*1e1,num=10000)\n",
    "    \n",
    "    best_amp = 0\n",
    "    int_flux = 0\n",
    "    \n",
    "    # Find the amplitude that makes the best-fit gaussian model by matching the integrated flux_to_fit\n",
    "    for amp in amp_array:\n",
    "        #print('Amplitude:',amp) # debugging\n",
    "        gaussian = models.Gaussian1D(amplitude=amp,mean=line_center,stddev=FWHM_wave/2.355)\n",
    "        model = gaussian(new_wave_grid)\n",
    "        int_flux = np.trapz(x=new_wave_grid,y=model)\n",
    "        #print('Flux:',int_flux) # debugging\n",
    "        best_amp = amp\n",
    "        if(int_flux >= flux_to_match):\n",
    "            break\n",
    "    \n",
    "    return new_wave_grid,model,best_amp,int_flux\n",
    "\n",
    "def minimize_scale_factor(ref,spectrum,init_factor,search_range):\n",
    "    # Minimizes the scale factor [(F_obs - F_proxy)/E_obs]^2. Returns the best scale factor \n",
    "    #      and the minimum \"chi^2\" value\n",
    "    # INPUT:\n",
    "    # ref = reference spectrum. numpy array including wavelength, flux, error [wave,flux,err]\n",
    "    # spectrum = spectrum to be scaled. 1d numpy array containing ONLY flux.\n",
    "    # init_factor = initial scaling factor\n",
    "    # search_range = order of magnitude to search around init_factor. ie: search_range = 2 will search for \n",
    "    #                factors between init_factor*10^(-2)-init_factor*10^(+2)\n",
    "    # OUTPUT:\n",
    "    # alpha scaling value and minimum \"chi squared\" factor\n",
    "    \n",
    "    scale_factors = np.linspace(init_factor*10**(-search_range),init_factor*10**(search_range),num=5000)\n",
    "    #print('Scale factor lims',min(scale_factors),max(scale_factors)) # debugging\n",
    "    best_factor = 1\n",
    "    min_chi2 = np.inf\n",
    "    \n",
    "    for alpha in scale_factors:\n",
    "        scaled_flux = spectrum*alpha\n",
    "        chi2 = np.sum(((ref[1]-scaled_flux)/ref[2])**2)/(len(ref[0])-1)\n",
    "        \n",
    "        if(chi2 < min_chi2):\n",
    "            min_chi2 = chi2\n",
    "            best_factor = alpha\n",
    "            \n",
    "    return best_factor,min_chi2\n",
    "\n",
    "def scale_spectrum(ref,spectrum,init_factor=1,coarse_range=2,fine_range=1,end='high'):\n",
    "    # Takes a reference spectrum and a spectrum to be scaled. Calls minimize_scale_factor and returns the best \n",
    "    #        scale factor to match the spectrum to the reference.\n",
    "    # INPUT:\n",
    "    # ref, spectrum, init_factor = same as minimize_scale_factor()\n",
    "    # coarse_range = value of search_range to be passed to minimize_scale_factor() for the initial search.\n",
    "    #                This is intended to search a braod range to avoid local minima\n",
    "    # fine_range = value of search_range to be passed to minimize_scale_factor() for the 2nd search.\n",
    "    #               This is intended to find a more precise minimum around the result from the coarse search\n",
    "    # end = which end of the REFERENCE spectrum are you scaling to. Must be 'low' or 'high' for blue \n",
    "    #               and red end respectively. \n",
    "    #               For BT-settl we scale the blue end of the spectrum to the red end of reference: end='high'\n",
    "    #               For proxy we scale the red end of spectrum to the blue end of G230L: end='low'\n",
    "    # OUTPUT:\n",
    "    # scaled spectrum in form [wavelength, flux*alpha, error*alpha]\n",
    "    # alpha scaling factor\n",
    "    # minimum \"chi squared\" factor\n",
    "    \n",
    "    # Get the region where the spectrum and reference overlap\n",
    "    if(end.lower()=='high'):\n",
    "        try:\n",
    "            ref_reg = ref[0] > spectrum[0][0]\n",
    "            spec_reg = spectrum[0] < ref[0][-1]\n",
    "            \n",
    "            ref = ref[:,ref_reg]\n",
    "            spectrum = spectrum[:,spec_reg]\n",
    "        except:\n",
    "            raise IndexError('For end=\\'high\\' the spectrum to be scaled must overlap with the red end of the reference')\n",
    "    elif(end.lower()=='low'):\n",
    "        try:\n",
    "            ref_reg = ref[0] < spectrum[0][-1]\n",
    "            spec_reg = spectrum[0] > ref[0][0]\n",
    "            \n",
    "            ref = ref[:,ref_reg]\n",
    "            spectrum = spectrum[:,spec_reg]\n",
    "        except:\n",
    "            raise IndexError('For end=\\'low\\' the spectrum to be scaled must overlap with the blue end of the reference')\n",
    "    else:\n",
    "        raise Exception('Keyword \\'end\\' must be \\'high\\' or \\'low\\'')\n",
    "        \n",
    "    # print the overlap region used in the scaling routine\n",
    "    print('Fitting region:\\t%0.1f-%0.1f'%(min(spectrum[0]),max(spectrum[0])))\n",
    "        \n",
    "    # Interpolate the spectrum with greater A/pix onto the wavelength grid of the other\n",
    "    ref_ang_per_pix = np.nanmean(np.diff(ref[0])/len(ref[0]))\n",
    "    spectrum_ang_per_pix = np.nanmean(np.diff(spectrum[0])/len(ref[0]))\n",
    "    \n",
    "    if((ref_ang_per_pix < spectrum_ang_per_pix) or (ref_ang_per_pix == spectrum_ang_per_pix)):\n",
    "        spectrum_interp = np.interp(x=ref[0],xp=spectrum[0],fp=spectrum[1])\n",
    "        \n",
    "        # Run the minimization routine with a broad, coarse search\n",
    "        scale_factor_coarse,_ = minimize_scale_factor(ref,spectrum_interp,init_factor,search_range=coarse_range)\n",
    "        # Run the minimization routine with a fine search around the initial factor\n",
    "        scale_factor,chi2 = minimize_scale_factor(ref,spectrum_interp,scale_factor_coarse,search_range=fine_range)\n",
    "        \n",
    "    elif(spectrum_ang_per_pix < ref_ang_per_pix):\n",
    "        ref_interp = np.interp(x=spectrum[0],xp=ref[0],fp=ref[1])\n",
    "        ref_err_interp = np.interp(x=spectrum[0],xp=ref[0],fp=ref[2])\n",
    "        \n",
    "        ref_to_pass = np.array([spectrum[0],ref_interp,ref_err_interp])\n",
    "        \n",
    "        # Run the minimization routine with a broad, coarse search\n",
    "        scale_factor_coarse,_ = minimize_scale_factor(ref_to_pass,spectrum[1],init_factor,search_range=coarse_range)\n",
    "        # Run the minimization routine with a fine search around the initial factor\n",
    "        scale_factor,chi2 = minimize_scale_factor(ref_to_pass,spectrum[1],scale_factor_coarse,search_range=fine_range)\n",
    "        \n",
    "    print('--- RESULTS ---')\n",
    "    print('Best scale factor:\\t%0.4e'%(scale_factor))\n",
    "    print('Minimum chi square:\\t%0.4e'%(chi2))\n",
    "    \n",
    "    return scale_factor,chi2\n",
    "\n",
    "# Bin the instrument bits. After binning the spectrum, if there are data in a single bin coming from multiple sources\n",
    "#     get_inst_bins() will add the instrument bits to indicate the separate sources\n",
    "def get_inst_bins(inst_array):\n",
    "    # INPUT: 1D instrument bit array from the spectrum being binned\n",
    "    # OUTPUT: scalar value representing the sum of the instrument bits in the bin\n",
    "    #             ie: A bin containing both proxy & G230L data will read 36 (4+32)\n",
    "    bin_val = np.sum(np.unique(inst_array))\n",
    "    return bin_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203dbac8",
   "metadata": {},
   "source": [
    "# Star & Proxy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88d88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update ###\n",
    "STAR = 'WASP-17'.upper()\n",
    "PROXY_NAME = 'Procyon'\n",
    "STELLAR_TYPE='F'\n",
    "STELLAR_RADIUS_SOL = 1.573\n",
    "STELLAR_DIST_PC = 410\n",
    "\n",
    "### Do not update ###\n",
    "SOLAR_DIST_PC = 4.8481e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c95436",
   "metadata": {},
   "source": [
    "# Read FITS files from star directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd12537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for G130M\n",
      "Did not find directory\n",
      "Searching for G140L\n",
      "Found directory: ./WASP-17\\G140L\n",
      "Retrieved G140L\n",
      "Searching for G140M\n",
      "Did not find directory\n",
      "Searching for G160M\n",
      "Did not find directory\n",
      "Searching for G230L\n",
      "Found directory: ./WASP-17\\G230L\n",
      "Retrieved G230L\n",
      "Searching for E230M\n",
      "Did not find directory\n",
      "Searching for G430L\n",
      "Found directory: ./WASP-17\\G430L\n",
      "Retrieved G430L\n",
      "Rerieved proxy\n",
      "\n",
      "Gratings list:\n",
      "{'G130M': False, 'G140L': True, 'G140M': False, 'G160M': False, 'G230L': True, 'E230M': False, 'G430L': True}\n"
     ]
    }
   ],
   "source": [
    "grating_exists = {'G130M':False,'G140L':False,'G140M':False,'G160M':False,'G230L':False,'E230M':False,'G430L':False,}\n",
    "gratings = {}\n",
    "\n",
    "# Get STIS spectra\n",
    "for grating_name in grating_exists.keys():\n",
    "    # Search for spectra from the appropriate grating and add it to the grating dictionary\n",
    "    grating_exists[grating_name] = look_for_data(STAR,grating_name,gratings)\n",
    "    \n",
    "# Retrieve proxy star spectrum\n",
    "try:\n",
    "    if(PROXY_NAME.lower()=='sun' or PROXY_NAME.lower()=='solar'):\n",
    "        solar_dat = readsav('./Proxy stars/Solar/solar-data.idlsav')\n",
    "        solar_wave = solar_dat['wave'][:,0]*10\n",
    "        solar_flux = solar_dat['flux'][:,0]*100\n",
    "        inst = INST_BITS['proxy']*np.ones(len(solar_wave))\n",
    "        \n",
    "        proxy = np.array([solar_wave,solar_flux,np.zeros(len(solar_wave)),inst])\n",
    "        print('Retrieved Solar proxy')\n",
    "    elif(PROXY_NAME.lower()=='procyon'):\n",
    "        with fits.open('./Proxy stars/Procyon/Procyon_SED_1Ang_5um.fits') as hdul:\n",
    "            wave = hdul[1].data['WAVE']\n",
    "            flux = hdul[1].data['FLUX']\n",
    "            err = np.zeros(len(wave))\n",
    "            inst = np.ones(len(wave))*INST_BITS['proxy']\n",
    "            \n",
    "            proxy = np.array([wave,flux,err,inst])\n",
    "            hdul.close()\n",
    "            \n",
    "        print('Rerieved proxy')\n",
    "    else:\n",
    "        for root,dirs,files in os.walk('./Proxy stars'):\n",
    "            if(root == './Proxy stars\\\\%s'%(PROXY_NAME)):\n",
    "                print('Found directory: %s'%(root))\n",
    "                \n",
    "                with fits.open('./Proxy stars/%s/%s'%(PROXY_NAME,files[0])) as hdul:\n",
    "                    wave = hdul[1].data['WAVELENGTH']\n",
    "                    flux = hdul[1].data['FLUX']\n",
    "                    err = hdul[1].data['ERROR']\n",
    "                    inst = INST_BITS['proxy']*np.ones(len(wave))\n",
    "                    \n",
    "                    proxy = np.array([wave,flux,err,inst])\n",
    "                    hdul.close()\n",
    "                    \n",
    "                print('Retrieved proxy')\n",
    "except:\n",
    "    print('Could not retrieve proxy')\n",
    "    \n",
    "print('\\nGratings list:')\n",
    "print(grating_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a9e5d",
   "metadata": {},
   "source": [
    "#### Special cases: ie: COS, uncommmon STIS gratings, etc, do manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83bac8e",
   "metadata": {},
   "source": [
    "## HD-149026 E230M spectrum ##\n",
    "# We're just gonna go ahead and replace gratings['G230L'] with E230M data. \n",
    "# I realize this is a bad way to do it\n",
    "# It's a one-off case, it'll be ok\n",
    "\n",
    "hd_dat = pd.read_csv('./HD-149026/E230M/HD-149026_E230M_x1d.csv')\n",
    "E230M_spectrum = np.array([hd_dat['wavelength'],hd_dat['flux'],hd_dat['error'],np.ones(len(hd_dat['flux']))*INST_BITS['E230M']])\n",
    "\n",
    "E230M_conv_flux = spf.convolve_gaussian(E230M_spectrum[0],E230M_spectrum[1],1.58)\n",
    "E230M_conv_err = spf.convolve_gaussian(E230M_spectrum[0],E230M_spectrum[2],1.58)\n",
    "E230M_spectrum[0],E230M_spectrum[1] = E230M_conv_flux[0],E230M_conv_flux[1]\n",
    "E230M_spectrum[2] = E230M_conv_err[1]\n",
    "\n",
    "gratings['G230L'] = E230M_spectrum\n",
    "print(gratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9a442",
   "metadata": {},
   "source": [
    "## L 678-39 COS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78571d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(gratings['G160M'][0],gratings['G160M'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e8324",
   "metadata": {},
   "source": [
    "# Examine data and select good regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c618d73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with G140L\n",
      "Keeping wavelengths from:  1683.50-1711.50\n",
      "Working with G230L\n",
      "Keeping wavelengths from:  1742.00-3163.50\n",
      "Working with G430L\n",
      "Keeping wavelengths from:  3172.00-5699.50\n"
     ]
    }
   ],
   "source": [
    "for grating_name in gratings:\n",
    "    print('Working with',grating_name)\n",
    "    grating = gratings[grating_name]\n",
    "    \n",
    "    # Get good error region for plottign SNR\n",
    "    good_err_reg = (grating[2] != 0)\n",
    "    \n",
    "    fig,ax = plt.subplots(2,1,figsize=(10,8),tight_layout=True,sharex=True,num=grating_name)\n",
    "    fig.suptitle(grating_name)\n",
    "    ax[0].plot(grating[0],grating[1])\n",
    "    ax[1].plot(grating[0][good_err_reg],grating[1][good_err_reg]/grating[2][good_err_reg])\n",
    "    ax[1].hlines(y=3,xmin=min(grating[0]),xmax=max(grating[0]),color='k',linestyle='--')\n",
    "    ax[1].set_ylim([-3,20])\n",
    "    \n",
    "    ax[1].set_xlabel('Wavelength [A]')\n",
    "    ax[0].set_ylabel('Flux [erg / s / cm^2 / A]')\n",
    "    ax[1].set_ylabel('S/N')\n",
    "    \n",
    "    clicks = np.array(fig.ginput(n=-1,timeout=0))[-2::][:,0]\n",
    "    \n",
    "    selected_region = (grating[0] > clicks[0]) & (grating[0] < clicks[1])\n",
    "    print('Keeping wavelengths from:  %0.2f-%0.2f'%(grating[0][selected_region][0],grating[0][selected_region][-1]))\n",
    "    \n",
    "    gratings[grating_name] = grating[:,selected_region]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73f151",
   "metadata": {},
   "source": [
    "## Retrieve Ly$\\alpha$ profile & BT-Settl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af064dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Mg II reconstruction\n",
      "Retrieved BT-Settl\n"
     ]
    }
   ],
   "source": [
    "# Lya\n",
    "try:\n",
    "    lya_data = pd.read_csv('./%s/lya_reconstruction/%s_G140M_MCMC_results.csv'%(STAR,STAR))\n",
    "    lya_err = np.mean((lya_data['lya_intrinsic_low_1sig'],lya_data['lya_intrinsic_high_1sig']),axis=0)\n",
    "    lya = np.array([lya_data['wave_lya'],\n",
    "                    lya_data['lya_intrinsic_median'],\n",
    "                    lya_err,\n",
    "                    np.ones(len(lya_data['wave_lya']))*INST_BITS['lya']])\n",
    "    print('Retrieved MCMC reconstruction')\n",
    "except:\n",
    "    try:\n",
    "        lya_data = pd.read_csv('./%s/lya_reconstruction/%s_lya_intrinsic_profile.csv'%(STAR,STAR))\n",
    "        lya = np.array([lya_data['wave'],\n",
    "                        lya_data['flux'],\n",
    "                        np.zeros(len(lya_data['wave'])),\n",
    "                        np.ones(len(lya_data['wave']))*INST_BITS['lya']])\n",
    "        print('Retrieved Mg II reconstruction')\n",
    "    except:\n",
    "        print('No Lyman-alpha profile found')\n",
    "        \n",
    "# BT-Settl\n",
    "try:\n",
    "    settl_dat = Table.read('./%s/interp_spectra/%s_phoenix_interpolated.ecsv'%(STAR,STAR))\n",
    "    settl = np.array([settl_dat['WAVELENGTH'],\n",
    "                      settl_dat['FLUX']*settl_dat.meta['NORMFAC'],\n",
    "                      np.zeros(len(settl_dat['FLUX'])),\n",
    "                      np.ones(len(settl_dat['WAVELENGTH']))*INST_BITS['BT-Settl']])\n",
    "    print('Retrieved BT-Settl')\n",
    "except:\n",
    "    print('No SETTL data found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a60b8d",
   "metadata": {},
   "source": [
    "# Convolve & Scale BT-Settl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c586101",
   "metadata": {},
   "source": [
    "#### Convolve BT-Settl to G430L Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85aebc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve BT-Settl to G430L resolution (~2.73A/pix [STIS handbook])\n",
    "settl_conv_flux = spf.convolve_gaussian(settl[0],settl[1],2.73)\n",
    "settl_conv = np.array([settl_conv_flux[0],settl_conv_flux[1],np.zeros(len(settl_conv_flux[0]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54c3d3",
   "metadata": {},
   "source": [
    "#### Scale convolved BT-Settl to G430L data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e2ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting region:\t5002.1-5697.9\n",
      "--- RESULTS ---\n",
      "Best scale factor:\t6.9988e-01\n",
      "Minimum chi square:\t4.2409e+01\n"
     ]
    }
   ],
   "source": [
    "# Select the region of the settl spectrum to scale and run the minimization routine. Recommend >5000A\n",
    "settl_to_fit = settl_conv[0] > 5000\n",
    "\n",
    "settl_alpha,settl_chi2 = scale_spectrum(ref=gratings['G430L'],spectrum=settl_conv[:,settl_to_fit],\n",
    "                                                init_factor=1,coarse_range=2,fine_range=0.5,end='high')\n",
    "\n",
    "scaled_settl = np.array([settl_conv[0],\n",
    "                         settl_conv[1]*settl_alpha,\n",
    "                         settl_conv[2]*settl_alpha,\n",
    "                         np.ones(len(settl_conv[0]))*INST_BITS['BT-Settl']])\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,6),tight_layout=True);\n",
    "spf.setup_axis(ax)\n",
    "ax.plot(gratings['G430L'][0],gratings['G430L'][1]*1e14,label='G430L');\n",
    "ax.plot(settl_conv[0],settl_conv[1]*settl_alpha*1e14,label=r'Scaled BT-Settl: $\\alpha$=%0.4f'%(settl_alpha),zorder=-1);\n",
    "#ax.plot(settl_conv[0],settl_conv[1],label='Unscaled SETTL');\n",
    "ax.legend(fontsize=12);\n",
    "\n",
    "ax.set_xlim([min(gratings['G430L'][0])-300,max(gratings['G430L'][0])+500]);\n",
    "ax.set_xlabel(r'Wavelength [$\\AA$]',fontsize=14);\n",
    "ax.set_ylabel(r'Flux density [10$^{-14}$ erg s$^{-1}$ cm${-2}$ Ã…$^{-1}$]',fontsize=14);\n",
    "\n",
    "plt.savefig('./%s/bt-settl_scaling.png'%(STAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8cb1b7",
   "metadata": {},
   "source": [
    "#### Scale proxy spectrum to G230L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd66531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting region:\t1742.5-2999.5\n",
      "--- RESULTS ---\n",
      "Best scale factor:\t2.3595e-05\n",
      "Minimum chi square:\t2.0217e+02\n"
     ]
    }
   ],
   "source": [
    "# Select the region of the proxy spectrum to scale and run the minimization routine, assuming we have a G230L spectrum\n",
    "# IGNORES MgII LINE\n",
    "grating_exists['G230L'] = True\n",
    "if(grating_exists['G230L']):\n",
    "    proxy_to_fit = (proxy[0] > gratings['G230L'][0][0]) & (proxy[0] < 3000)\n",
    "    mg2_reg = [2770,2820]\n",
    "    \n",
    "    proxy_mg = (proxy[0] > mg2_reg[0]) & (proxy[0] < mg2_reg[1])\n",
    "    stis_mg = (gratings['G230L'][0] > mg2_reg[0]) & (gratings['G230L'][0] < mg2_reg[1])\n",
    "    \n",
    "\n",
    "    if((PROXY_NAME.upper()=='SUN') or (PROXY_NAME.upper()=='SOLAR')):\n",
    "        \n",
    "        # If the proxy is the Sun, scale it by (d_Sun/d_star)^2\n",
    "        #     to get the minimization to converge\n",
    "        init_proxy = proxy[:,proxy_to_fit^proxy_mg]\n",
    "        scale_fac = (SOLAR_DIST_PC/STELLAR_DIST_PC)**2\n",
    "        print('initial scale factor:',scale_fac)\n",
    "        init_proxy[1] = init_proxy[1]*scale_fac\n",
    "\n",
    "        proxy_alpha,proxy_chi2 = scale_spectrum(ref=gratings['G230L'][:,~stis_mg],spectrum=init_proxy,\n",
    "                                                        init_factor=1,coarse_range=3,fine_range=0.5,end='low')\n",
    "\n",
    "        proxy_alpha=proxy_alpha*scale_fac\n",
    "        \n",
    "        scaled_proxy = np.array([proxy[0],\n",
    "                                 proxy[1]*proxy_alpha,\n",
    "                                 proxy[2]*proxy_alpha,\n",
    "                                 np.ones(len(proxy[0]))*INST_BITS['proxy']])\n",
    "        \n",
    "        fig,ax = plt.subplots(1,1,figsize=(10,6),tight_layout=True)\n",
    "        ax.plot(gratings['G230L'][0],gratings['G230L'][1],label='G230L')\n",
    "        ax.plot(scaled_proxy[0],scaled_proxy[1],label=r'Scaled proxy: $\\alpha$=%0.4e'%(proxy_alpha))\n",
    "        ax.legend()\n",
    "\n",
    "        ax.set_xlim([min(proxy[0][proxy_to_fit]),max(gratings['G230L'][0])])\n",
    "\n",
    "        ax.set_xlabel(r'Wavelength [$\\AA$]')\n",
    "        ax.set_ylabel(r'Flux density [erg s$^{-1}$ cm${-2}$ $\\AA^{-1}$]')\n",
    "\n",
    "        print('EXCEPTION: SOLAR PROXY')\n",
    "        print('Acutal scale factor:\\t%0.4e'%(proxy_alpha))\n",
    "        \n",
    "    else:\n",
    "        proxy_alpha,proxy_chi2 = scale_spectrum(ref=gratings['G230L'][:,~stis_mg],\n",
    "                                                             spectrum=proxy[:,proxy_to_fit^proxy_mg],\n",
    "                                                        init_factor=0.01,coarse_range=3,fine_range=0.5,end='low')\n",
    "\n",
    "        scaled_proxy = np.array([proxy[0],\n",
    "                                 proxy[1]*proxy_alpha,\n",
    "                                 proxy[2]*proxy_alpha,\n",
    "                                 np.ones(len(proxy[0]))*INST_BITS['proxy']])\n",
    "        \n",
    "        \n",
    "        fig,ax = plt.subplots(1,1,figsize=(10,6),tight_layout=True);\n",
    "        ax.plot(gratings['G230L'][0],gratings['G230L'][1],label='G230L');\n",
    "        ax.plot(scaled_proxy[0],scaled_proxy[1],label=r'Scaled proxy: $\\alpha$=%0.4e'%(proxy_alpha));\n",
    "        ax.legend();\n",
    "\n",
    "        ax.set_xlim([min(proxy[0][proxy_to_fit]),max(gratings['G230L'][0])]);\n",
    "\n",
    "        ax.set_xlabel(r'Wavelength [$\\AA$]');\n",
    "        ax.set_ylabel(r'Flux density [erg s$^{-1}$ cm${-2}$ $\\AA^{-1}$]');\n",
    "        \n",
    "plt.savefig('./%s/proxy_scaling.png'%(STAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310621fe",
   "metadata": {},
   "source": [
    "# Get EUV bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7107ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stellar type: F\n",
      "Distance: 410pc\n",
      "Integrated lya flux:\t\t2.8508e-15 erg/s/cm^2\n",
      "Integrated lya flux at 1AU:\t2.0389e+01 erg/s/cm^2\n",
      "Bin 100-200:\t3.5351e-18 erg/s/cm^2/A\n",
      "Bin 200-300:\t3.6272e-18 erg/s/cm^2/A\n",
      "Bin 300-400:\t3.7408e-18 erg/s/cm^2/A\n",
      "Bin 400-500:\t3.1535e-19 erg/s/cm^2/A\n",
      "Bin 500-600:\t1.2763e-18 erg/s/cm^2/A\n",
      "Bin 600-700:\t7.0668e-19 erg/s/cm^2/A\n",
      "Bin 700-800:\t1.7347e-18 erg/s/cm^2/A\n",
      "Bin 800-912:\t3.9366e-18 erg/s/cm^2/A\n",
      "Bin 912-1170:\t1.3319e-18 erg/s/cm^2/A\n"
     ]
    }
   ],
   "source": [
    "#### EUV bin relations from Linsky et al (2014). Use integrated lyman-a flux to calculate 100-1170A flux density\n",
    "\n",
    "print('Stellar type:',STELLAR_TYPE)\n",
    "print('Distance: %dpc'%(STELLAR_DIST_PC))\n",
    "\n",
    "### Get Lya flux & scale to 1AU ###\n",
    "lya_scale_fac = (STELLAR_DIST_PC*pc2au)**2\n",
    "int_lya_flux = np.trapz(x=lya[0],y=lya[1])\n",
    "# Proxy lya flux\n",
    "#int_lya_flux = np.trapz(x=proxy[0][(proxy[0] > 1214) & (proxy[0] < 1217.4)],y=proxy[1][(proxy[0] > 1214) & (proxy[0] < 1217.4)]*proxy_alpha)\n",
    "print('Integrated lya flux:\\t\\t%0.4e erg/s/cm^2'%(int_lya_flux))\n",
    "\n",
    "int_lya_flux = int_lya_flux*lya_scale_fac\n",
    "print('Integrated lya flux at 1AU:\\t%0.4e erg/s/cm^2'%(int_lya_flux))\n",
    "\n",
    "# Use Linsky 2014 relations for EUV bins. Relations hold for F-M stars\n",
    "SUPPORTED_STELLAR_TYPES = ['M','K','G','F']\n",
    "\n",
    "# Bins 100-400 are different for M stars and F-K stars\n",
    "if(STELLAR_TYPE.upper() in SUPPORTED_STELLAR_TYPES):\n",
    "    if(STELLAR_TYPE.upper()=='M'):\n",
    "        bin_100_200 = 10**(-0.491)*int_lya_flux/100/lya_scale_fac\n",
    "        bin_200_300 = 10**(-0.548)*int_lya_flux/100/lya_scale_fac\n",
    "        bin_300_400 = 10**(-0.602)*int_lya_flux/100/lya_scale_fac\n",
    "\n",
    "    elif(STELLAR_TYPE.upper()=='K' or STELLAR_TYPE.upper()=='F' or STELLAR_TYPE.upper()=='G'):\n",
    "        bin_100_200 = 10**(-1.357)*int_lya_flux**(0.344+1)/100/lya_scale_fac\n",
    "        bin_200_300 = 10**(-1.300)*int_lya_flux**(0.309+1)/100/lya_scale_fac\n",
    "        bin_300_400 = 10**(-0.882)*int_lya_flux/100/lya_scale_fac\n",
    "    else:\n",
    "        print('How did you get here? Stellar type must be one of: \\'M\\' \\'K\\' \\'G\\' \\'F\\'')\n",
    "\n",
    "    # Bins 400-1170 are the same for all stars.\n",
    "    bin_400_500 = 10**(-2.294)*int_lya_flux**(0.258+1)/100/lya_scale_fac\n",
    "    bin_500_600 = 10**(-2.098)*int_lya_flux**(0.572+1)/100/lya_scale_fac\n",
    "    bin_600_700 = 10**(-1.920)*int_lya_flux**(0.240+1)/100/lya_scale_fac\n",
    "    bin_700_800 = 10**(-1.894)*int_lya_flux**(0.518+1)/100/lya_scale_fac\n",
    "    bin_800_912 = 10**(-1.811)*int_lya_flux**(0.764+1)/112/lya_scale_fac\n",
    "    bin_912_1170 = 10**(-1.004)*int_lya_flux**(0.065+1)/258/lya_scale_fac\n",
    "\n",
    "    bin_edges = np.array([100,200,300,400,500,600,700,800,912,1170])\n",
    "    bin_fluxes = np.array([bin_100_200,bin_200_300,bin_300_400,bin_400_500,\n",
    "                          bin_500_600,bin_600_700,bin_700_800,bin_800_912,bin_912_1170])\n",
    "\n",
    "    # Define a new wavelength array for the EUV bins to replace the proxy data\n",
    "    euv_reg = (proxy[0] > 100) & (proxy[0] < 1170)\n",
    "    EUV_wave_array = proxy[0][euv_reg]\n",
    "    EUV_flux_array = np.ones(len(EUV_wave_array))\n",
    "    EUV_inst_array = np.ones(len(EUV_wave_array))*INST_BITS['EUV']\n",
    "\n",
    "    for i in range(len(bin_fluxes)):\n",
    "        print('Bin %d-%d:\\t%0.4e erg/s/cm^2/A'%(bin_edges[i],bin_edges[i+1],bin_fluxes[i]))\n",
    "        current_bin = (EUV_wave_array >= bin_edges[i]) & (EUV_wave_array < bin_edges[i+1])\n",
    "        EUV_flux_array[current_bin] = bin_fluxes[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(12,8),tight_layout=True);\n",
    "    ax = fig.add_subplot();\n",
    "    [x.set_linewidth(1.5) for x in ax.spines.values()];\n",
    "    ax.tick_params(which='both',direction='in',top=True,right=True,length=7,width=1.5,labelsize=12);\n",
    "    ax.tick_params(which='minor',length=4,width=1.5);\n",
    "    ax.minorticks_on()\n",
    "    plt.step(EUV_wave_array,EUV_flux_array);\n",
    "    plt.title('EUV flux bins',fontsize=15);\n",
    "    plt.yscale('log');\n",
    "    plt.grid(which='both',axis='both',alpha=0.4);\n",
    "    plt.xlabel('Wavelength [A]',fontsize=14);\n",
    "    plt.ylabel('Flux density [erg / s / cm^2 / A]',fontsize=14);\n",
    "    \n",
    "else:\n",
    "    print('Unsupported stellar type. Skipping EUV bins')\n",
    "    \n",
    "    \n",
    "EUV_data = np.array([EUV_wave_array,\n",
    "                     EUV_flux_array,\n",
    "                     np.zeros(len(EUV_wave_array)),\n",
    "                     EUV_inst_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8e85aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 200]\n",
      "[200 300]\n",
      "[300 400]\n",
      "[400 500]\n",
      "[500 600]\n",
      "[600 700]\n",
      "[700 800]\n",
      "[800 912]\n",
      "[ 912 1170]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x234216efb80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(scaled_proxy[0],scaled_proxy[1],c='C1')\n",
    "\n",
    "binRegs = np.array([[100,200],[200,300],[300,400],\n",
    "                    [400,500],[500,600],[600,700],\n",
    "                    [700,800],[800,912],[912,1170]],ndmin=2)\n",
    "for reg in binRegs:\n",
    "    print(reg)\n",
    "    reg_to_int = (scaled_proxy[0] > reg[0]) & (scaled_proxy[0] < reg[1])\n",
    "    bin_flux = np.trapz(x=scaled_proxy[0][reg_to_int],y=scaled_proxy[1][reg_to_int])/(reg[1]-reg[0])\n",
    "    plt.plot([reg[0],reg[1]],[bin_flux,bin_flux],c='C2')\n",
    "    \n",
    "legend_lines = [Line2D([0],[0],color='C0'),\n",
    "               Line2D([0],[0],color='C1'),\n",
    "               Line2D([0],[0],color='C2')]\n",
    "legend_handles = ['EUV estimation','Scaled proxy','Integrated proxy bins']\n",
    "plt.legend(legend_lines,legend_handles,fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a7ced",
   "metadata": {},
   "source": [
    "# Get X-ray spectrum (somewhat obsolete since we're using PIMMS now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f19b4e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong so we used the scaled proxy instead!\n"
     ]
    }
   ],
   "source": [
    "# get_aeff retrieves effective area from arf file. Only use this if you did not use 'setplot area' in XSPEC\n",
    "get_aeff = False\n",
    "\n",
    "\n",
    "try:\n",
    "    if(get_aeff):\n",
    "        d = 3.09e18*10 # distance in cm\n",
    "\n",
    "        with fits.open('./L-98-59/XMM/flare_analysis/F301/src_quiesfilt_0.3-10kev_arf.fits') as hdul:\n",
    "            resp_energy = hdul[1].data['ENERG_LO']\n",
    "            a_eff = hdul[1].data['SPECRESP']\n",
    "\n",
    "\n",
    "        closest_energy = np.zeros(len(x_ray_obs['energy']),dtype=int)\n",
    "\n",
    "\n",
    "        #### Get the closest energy value to the observed bins & divide by the effective area at that energy\n",
    "        for i in range(len(x_ray_obs['energy'])):\n",
    "            closest_energy[i] = int(np.argmin(np.abs(resp_energy-x_ray_obs['energy'][i])))\n",
    "            print('Energy:\\t%0.2fkeV\\nA_eff:\\t%0.1fcm^2'%(resp_energy[closest_energy[i]],a_eff[closest_energy[i]]))\n",
    "\n",
    "        fig,ax = plt.subplots(1,1,tight_layout=True,figsize=(9,7));\n",
    "        [x.set_linewidth(1.2) for x in ax.spines.values()]\n",
    "        ax.tick_params(which='both',direction='in',top=True,right=True,length=7,width=1.5,labelsize=12);\n",
    "        ax.tick_params(which='minor',length=4,width=1.0);\n",
    "        ax.minorticks_on();\n",
    "        ax.plot(APEC_model['energy'],APEC_model['model_flux'],label='APEC plasma model',zorder=-1);\n",
    "        ax.errorbar(x=x_ray_obs['energy'],y=x_ray_obs['counts'],\n",
    "                    xerr=x_ray_obs['bin_width'],yerr=x_ray_obs['counts_err'],\n",
    "                    linestyle='',label='X-ray observation',zorder=0);\n",
    "        ax.set_ylabel(r'Counts / s / cm$^2$ / keV',fontsize=14);\n",
    "        ax.set_xlabel('Energy [keV]',fontsize=14);\n",
    "        ax.legend(fontsize=12)\n",
    "\n",
    "    #### TODO\n",
    "    #### COME UP WITH A WAY TO AUTOMATE RETRIEVAL OF X-RAY DATA & XSPEC MODELS\n",
    "\n",
    "    ####### x-ray model CSV contains ########\n",
    "    # Energy [keV]  |  energy bin width [keV]  |  total counts  |  counts error  |  photon flux [photon/s/cm^2/keV]\n",
    "    #########################################\n",
    "\n",
    "\n",
    "    x_ray_data = pd.read_csv('./L-98-59/XMM/flare_analysis/F301/x_ray_model.csv',delimiter=',')\n",
    "\n",
    "    end_of_data = 0\n",
    "    start_of_APEC = 0\n",
    "    for row,index in zip(x_ray_data['energy'],range(len(x_ray_data['energy']))):\n",
    "        print(index,row)\n",
    "        if(row.lower()=='break'):\n",
    "            # Subtract 1 from index because pandas range is inclusive(?)\n",
    "            end_of_data = index-1\n",
    "            start_of_APEC = index+1\n",
    "            print('Data ends at:',index)\n",
    "            break\n",
    "\n",
    "    x_ray_obs = x_ray_data.loc[0:end_of_data].astype(float)\n",
    "    print(x_ray_obs)\n",
    "    APEC_model = x_ray_data.loc[start_of_APEC::].astype(float)\n",
    "    print(APEC_model)\n",
    "\n",
    "\n",
    "    obs_energy = np.array(x_ray_obs['energy'])[::-1]\n",
    "\n",
    "    obs_wave = np.array(h*c/obs_energy)\n",
    "    obs_flux = np.array(x_ray_obs['counts'][::-1]*obs_energy)*erg*obs_energy**2/(h*c)\n",
    "    obs_err = np.array(x_ray_obs['counts_err'][::-1]*obs_energy*erg*obs_energy**2/(h*c))\n",
    "\n",
    "\n",
    "    apec_energy = np.array(APEC_model['energy'])[::-1]\n",
    "    apec_wave = h*c/apec_energy\n",
    "    apec_flux = np.array(APEC_model['model_flux'][::-1])*erg*apec_energy**2/(h*c)\n",
    "\n",
    "    fig,ax = plt.subplots(1,1,figsize=(10,7),tight_layout=True)\n",
    "    ax.errorbar(x=obs_wave,\n",
    "                y=obs_flux,\n",
    "                xerr=np.sqrt((-h*c/obs_energy**2)**2*x_ray_obs['bin_width'][::-1]**2),\n",
    "                yerr=obs_err,linestyle='',label=STAR,zorder=2)\n",
    "    ax.plot(apec_wave,apec_flux,label='APEC',zorder=1)\n",
    "    ax.plot(wave,flux*proxy_alpha,label='Scaled proxy',zorder=0)\n",
    "    ax.set_xlabel('Wavelength [Ã…]')\n",
    "    ax.set_ylabel('erg / s / cm^2 / A')\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.minorticks_on()\n",
    "    ax.legend()\n",
    "\n",
    "    fig.suptitle(STAR)\n",
    "\n",
    "    apec_region1 = (apec_wave > 5.) & (apec_wave < obs_wave[1])\n",
    "    apec_region2 = (apec_wave > obs_wave[-1]) & (apec_wave < 100)\n",
    "    apec_region = apec_region1+apec_region2\n",
    "\n",
    "    apec_data = np.array([apec_wave[apec_region],\n",
    "                          apec_flux[apec_region],\n",
    "                          np.zeros(np.sum(apec_region)),\n",
    "                          np.ones(np.sum(apec_region))*INST_BITS['APEC']])\n",
    "\n",
    "\n",
    "    obs_data = np.array([obs_wave[1::],\n",
    "                         obs_flux[1::],\n",
    "                         obs_err[1::],\n",
    "                         np.ones(len(obs_wave[1::]))*INST_BITS['X-RAY']])\n",
    "\n",
    "    xray_data = np.concatenate((apec_data,obs_data),axis=1)\n",
    "except:\n",
    "    x_ray_reg = (scaled_proxy[0] > 5) & (scaled_proxy[0] < 100)\n",
    "    xray_data = scaled_proxy[:,x_ray_reg]\n",
    "    print('Something went wrong so we used the scaled proxy instead!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0614e5",
   "metadata": {},
   "source": [
    "# Put the pieces together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f632422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is a gap between G230L & G430L, fill it with the proxy\n",
    "if(gratings['G430L'][0][0] > gratings['G230L'][0][-1]):\n",
    "    #### Obs UV data\n",
    "    # gratings['G230L'],  gratings['G430L']\n",
    "    STIS_data = np.concatenate((gratings['G140L'],gratings['G230L'],gratings['G430L']),axis=1)\n",
    "    #STIS_data = gratings['G430L']\n",
    "    plt.plot(STIS_data[0],STIS_data[1],label='STIS')\n",
    "\n",
    "    #### Proxy data\n",
    "    # scaled_proxy\n",
    "    proxy_region1 = (scaled_proxy[0] > 1170.) & (scaled_proxy[0] < gratings['G140L'][0][0])\n",
    "    proxy_region2 = (scaled_proxy[0] > gratings['G140L'][0][-1]) & (scaled_proxy[0] < gratings['G230L'][0][0])\n",
    "    proxy_region3 = (scaled_proxy[0] > gratings['G230L'][0][-1]) & (scaled_proxy[0] < gratings['G430L'][0][0])\n",
    "    proxy_region = proxy_region1+proxy_region2+proxy_region3\n",
    "    proxy_data = scaled_proxy[:,proxy_region]\n",
    "\n",
    "    plt.plot(proxy_data[0],proxy_data[1])\n",
    "\n",
    "    #### BT-Settl\n",
    "    # scaled_settl\n",
    "    settl_region = (scaled_settl[0] > gratings['G430L'][0][-1]) & (scaled_settl[0] < 55000)\n",
    "\n",
    "    settl_data = scaled_settl[:,settl_region]\n",
    "\n",
    "    plt.plot(settl_data[0],settl_data[1])\n",
    "\n",
    "    #### EUV data\n",
    "    # EUV_data\n",
    "    plt.plot(EUV_data[0],EUV_data[1])\n",
    "\n",
    "    #### X-ray data\n",
    "    # xray_data\n",
    "    plt.errorbar(x=xray_data[0],y=xray_data[1],yerr=xray_data[2])\n",
    "\n",
    "    # Combine each data set into a single array\n",
    "    combined_spectrum_nolines = np.concatenate((xray_data,\n",
    "                                               EUV_data,\n",
    "                                               proxy_data,\n",
    "                                               STIS_data,\n",
    "                                               settl_data),axis=1)\n",
    "\n",
    "    # Get the sorted indices of the wavelength array using argsort and use that to sort the entire combined array\n",
    "    combined_spectrum_nolines = combined_spectrum_nolines[:,np.argsort(combined_spectrum_nolines[0])]\n",
    "\n",
    "\n",
    "    # Turn the combined_spectrum_nolines into a Spectrum1D for ease of inserting emission lines\n",
    "    combined_spec1d = Spectrum1D(spectral_axis=combined_spectrum_nolines[0]*u.AA,\n",
    "                                 flux=combined_spectrum_nolines[1]*u.Unit('erg cm-2 s-1 AA-1'),\n",
    "                                 uncertainty=StdDevUncertainty(combined_spectrum_nolines[2]))\n",
    "# If there is NO gap between G230L and G430L, use all of G430L\n",
    "else:\n",
    "    #### Obs UV data\n",
    "    # gratings['G230L'],  gratings['G430L']\n",
    "    g230_to_use = gratings['G230L'][0] < gratings['G430L'][0][0]\n",
    "    STIS_data = np.concatenate((gratings['G230L'][:,g230_to_use],gratings['G430L']),axis=1)\n",
    "    plt.plot(STIS_data[0],STIS_data[1],label='STIS')\n",
    "\n",
    "    #### Proxy data\n",
    "    # scaled_proxy\n",
    "    proxy_region = (scaled_proxy[0] > 1170.) & (scaled_proxy[0] < gratings['G230L'][0][0])\n",
    "\n",
    "    proxy_data = scaled_proxy[:,proxy_region]\n",
    "\n",
    "    plt.plot(proxy_data[0],proxy_data[1])\n",
    "\n",
    "    #### BT-Settl\n",
    "    # scaled_settl\n",
    "    settl_region = (scaled_settl[0] > gratings['G430L'][0][-1]) & (scaled_settl[0] < 55000)\n",
    "\n",
    "    settl_data = scaled_settl[:,settl_region]\n",
    "\n",
    "    plt.plot(settl_data[0],settl_data[1])\n",
    "\n",
    "    #### EUV data\n",
    "    # EUV_data\n",
    "    plt.plot(EUV_data[0],EUV_data[1])\n",
    "\n",
    "    #### X-ray data\n",
    "    # xray_data\n",
    "    plt.errorbar(x=xray_data[0],y=xray_data[1],yerr=xray_data[2])\n",
    "\n",
    "    # Combine each data set into a single array\n",
    "    combined_spectrum_nolines = np.concatenate((xray_data,\n",
    "                                               EUV_data,\n",
    "                                               proxy_data,\n",
    "                                               STIS_data,\n",
    "                                               settl_data),axis=1)\n",
    "\n",
    "    # Get the sorted indices of the wavelength array using argsort and use that to sort the entire combined array\n",
    "    combined_spectrum_nolines = combined_spectrum_nolines[:,np.argsort(combined_spectrum_nolines[0])]\n",
    "\n",
    "\n",
    "    # Turn the combined_spectrum_nolines into a Spectrum1D for ease of inserting emission lines\n",
    "    combined_spec1d = Spectrum1D(spectral_axis=combined_spectrum_nolines[0]*u.AA,\n",
    "                                 flux=combined_spectrum_nolines[1]*u.Unit('erg cm-2 s-1 AA-1'),\n",
    "                                 uncertainty=StdDevUncertainty(combined_spectrum_nolines[2]))\n",
    "\n",
    "result = np.copy(combined_spectrum_nolines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250af20",
   "metadata": {},
   "source": [
    "# Replace Lya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ba0651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pabe9855\\AppData\\Local\\Temp/ipykernel_16352/2742923712.py:8: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ax[1].plot(result[0],result[1]/result[2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d6cb92eaf0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Lya first\n",
    "lya_region = (result[0] > lya[0][0]) & (result[0] < lya[0][-1])\n",
    "result = spf.replace(result,lya)\n",
    "\n",
    "fig,ax = plt.subplots(3,1,figsize=(7,7),tight_layout=True,sharex=True)\n",
    "spf.setup_axis(ax)\n",
    "ax[0].plot(result[0],result[1])\n",
    "ax[1].plot(result[0],result[1]/result[2])\n",
    "ax[2].plot(result[0],result[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1d330",
   "metadata": {},
   "source": [
    "# Create Emission Lines\n",
    "\n",
    "Have to do this one by hand for each star, unfortunately\n",
    "\n",
    "1) Update line dictionary with correct fluxes\n",
    "\n",
    "2) Update inst_bit with correct instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ae07da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238.8\n",
      "1242.8\n",
      "1393.76\n",
      "1402.77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d6d52283a0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary of lines in the form {line center:integrated flux}\n",
    "lines = {1238.8:5.14e-18,1242.8:1.099e-17,1393.76:1.32e-17,1402.77:8.13e-18}\n",
    "instruments = ['G140L','G140L','G140L','G140L']\n",
    "\n",
    "result = np.copy(combined_spectrum_nolines)\n",
    "bkg_poly_array = [] # Store the background polynomials to replace regions where the emission doesn't line up well with the continuum\n",
    "\n",
    "# For each line,flux combo, make a gaussian emission line and replace that portion of the spectrum.\n",
    "for line,flux,inst in zip(lines.keys(),lines.values(),instruments):\n",
    "    \n",
    "    print(line)\n",
    "    \n",
    "    inst_bit = INST_BITS[inst]\n",
    "    \n",
    "    wave_,flux_,best_amp,int_flux = make_emission_line(line,flux)\n",
    "    \n",
    "    # Get a background continuum to add emission line to\n",
    "    plt.figure()\n",
    "    plt.plot(scaled_proxy[0],scaled_proxy[1])\n",
    "    \n",
    "    line_points = np.asarray(plt.ginput(n=-1,timeout=0))[-2::]\n",
    "    bkg_points = np.asarray(plt.ginput(n=-1,timeout=0))[-2::]\n",
    "    \n",
    "    line_reg = (result[0] > line_points[0][0]) & (result[0] < line_points[1][0])\n",
    "    bkg_reg = (result[0] > bkg_points[0][0]) & (result[0] < bkg_points[1][0])\n",
    "    \n",
    "    wave_reg = bkg_reg^line_reg\n",
    "    \n",
    "    if(line < 1300):\n",
    "        deg = 2\n",
    "    else:\n",
    "        deg = 1\n",
    "        \n",
    "    bkg_pparams = np.polyfit(x=result[0][wave_reg],y=result[1][wave_reg],deg=deg)\n",
    "    bkg_poly = np.poly1d(bkg_pparams)\n",
    "    \n",
    "    bkg_poly_array.append(bkg_poly)\n",
    "    \n",
    "    line_model = np.array([wave_,\n",
    "                           flux_+bkg_poly(wave_),\n",
    "                           np.zeros(len(wave_)),\n",
    "                           np.ones(len(wave_))*inst_bit])\n",
    "    \n",
    "    plt.plot(result[0][wave_reg],bkg_poly(result[0][wave_reg]))\n",
    "    plt.plot(line_model[0],line_model[1])\n",
    "    \n",
    "    result = spf.replace(result,line_model)\n",
    "    \n",
    "    \n",
    "plt.figure(num='replaced')\n",
    "plt.plot(result[0],result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "251b8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace regions where the line doesn't fit in well with the continuum using the background fits\n",
    "reg1 = [1239.8,1241.64]\n",
    "reg2 = [1244.11,1245.95]\n",
    "\n",
    "x = np.arange(reg2[0],reg2[1],step=0.5)\n",
    "\n",
    "bkg_replace = np.array([x,\n",
    "                       bkg_poly_array[1](x),\n",
    "                       np.zeros(len(x)),\n",
    "                       np.ones(len(x))*INST_BITS['G140L']])\n",
    "\n",
    "result = spf.replace(result,bkg_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86a2adec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1d6da27bc70>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "ax1 = plt.subplot(211)\n",
    "spf.setup_axis(ax1)\n",
    "plt.plot(gratings['G140L'][0],gratings['G140L'][1])\n",
    "plt.plot(scaled_proxy[0],scaled_proxy[1])\n",
    "plt.plot(result[0],result[1])\n",
    "ax2 = plt.subplot(212,sharex=ax1)\n",
    "spf.setup_axis(ax2)\n",
    "ax2.plot(result[0],result[3])\n",
    "plt.plot(gratings['G140L'][0],gratings['G140L'][1]/gratings['G140L'][2])\n",
    "plt.ylim([-1,6])\n",
    "plt.axhline(y=3,c='k',linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd04a3",
   "metadata": {},
   "source": [
    "# Replace emission regions with STIS (WASP-77A, L 98-59, HD 149026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(6,6),sharex=True)\n",
    "spf.setup_axis(ax)\n",
    "#ax[0].plot(gratings['G140L'][0],gratings['G140L'][1])\n",
    "#ax[1].plot(gratings['G140L'][0],gratings['G140L'][1]/gratings['G140L'][2])\n",
    "#ax[0].plot(gratings['G230L'][0],gratings['G230L'][1])\n",
    "#ax[1].set_ylim(-1,10)\n",
    "#ax[1].axhline(y=3,linestyle='--',color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35197c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[0].plot(result[0],result[1])\n",
    "ax[1].plot(result[0],result[1]/result[2])\n",
    "ax[1].set_ylim(-1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42536bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G140M_lines = np.array([[]])\n",
    "\n",
    "#G140L_lines = np.array([[1173.5,1180.1],\n",
    "#                        [1263.1,1268.1],\n",
    "#                        [1302.6,1313.0],\n",
    "#                        [1387.3,1405.6],\n",
    "#                        [1542.7,1563.9]])\n",
    "\n",
    "G230L_lines = np.array([[2786.0,2815.0]])\n",
    "\n",
    "#result = np.copy(combined_spectrum_nolines)\n",
    "try:\n",
    "    for line in G140M_lines:\n",
    "        region = (gratings['G140M'][0] > line[0]) & (gratings['G140M'][0] < line[1])\n",
    "\n",
    "        result = spf.replace(result,gratings['G140M'][:,region])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    for line in G140L_lines:\n",
    "        region = (gratings['G140L'][0] > line[0]) & (gratings['G140L'][0] < line[1])\n",
    "\n",
    "        result = spf.replace(result,gratings['G140L'][:,region])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    for line in G230L_lines:\n",
    "        region = (gratings['G230L'][0] > line[0]) & (gratings['G230L'][0] < line[1])\n",
    "\n",
    "        result = spf.replace(result,gratings['G230L'][:,region])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(combined_spectrum_nolines[0],combined_spectrum_nolines[1])\n",
    "plt.plot(result[0],result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0296a2f",
   "metadata": {},
   "source": [
    "# Make FITS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39c18f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pabe9855\\AppData\\Local\\Temp/ipykernel_16352/1619723731.py:9: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ax[1].step(result[0],result[1]/result[2],where='mid')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Instrument bit')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Double check plot to make sure you're happy!! \n",
    "\n",
    "fig,ax = plt.subplots(3,1,figsize=(9,9),tight_layout=True,sharex=True)\n",
    "spf.setup_axis(ax)\n",
    "\n",
    "pos_flux = result[2] > 0\n",
    "\n",
    "ax[0].step(result[0],result[1]*1e13,where='mid')\n",
    "ax[1].step(result[0],result[1]/result[2],where='mid')\n",
    "ax[2].step(result[0],result[3],where='mid')\n",
    "\n",
    "ax[0].set_ylabel(r'Flux density [10$^{-13}$ erg / s / cm$^{2}$ / Ã…]')\n",
    "ax[1].set_ylabel('SNR')\n",
    "ax[2].set_ylabel('Instrument bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387d5c8",
   "metadata": {},
   "source": [
    "### Mask parts if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08494eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (result[0] > 3384.77) & (result[0] < 3392.4)\n",
    "region = (result[0] > 3379.8) & (result[0] < 3403.04)\n",
    "mask_spline = UnivariateSpline(x=result[0][region^mask],\n",
    "                               y=result[1][region^mask],k=4)\n",
    "x = np.linspace(3368,3403)\n",
    "ax[0].plot(x,mask_spline(x)*1e13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[1,mask] = mask_spline(result[0,mask])\n",
    "ax[0].plot(result[0,region],result[1,region]*1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6898b",
   "metadata": {},
   "source": [
    "####### REPLACE EMISSION AT ~1300 FOR HAT-P-26 WITH RMS OF CONTINUUM ###########\n",
    "\n",
    "region = (result[0] > 1300.7) & (result[0] < 1308.9)\n",
    "rms_region = (result[0] > 1312) & (result[0] < 1330)\n",
    "rms = np.sqrt(np.mean(result[1][rms_region]**2))*np.ones(np.sum(region))\n",
    "result[1,region] = rms\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ebca3",
   "metadata": {},
   "source": [
    "### Write to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f51dc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = './%s/%s_combined_x1d_FINAL_FIXG430LSPIKE.fits'%(STAR,STAR)\n",
    "\n",
    "hdr = fits.Header()\n",
    "hdr['COMMENT'] = '%s 1D spectrum'%(STAR)\n",
    "\n",
    "primary = fits.PrimaryHDU(header=hdr)\n",
    "\n",
    "hduA = fits.BinTableHDU.from_columns([\n",
    "    fits.Column(name = 'WAVELENGTH',format='D',array=result[0]),\n",
    "    fits.Column(name = 'FLUX',format='D',array=result[1]),\n",
    "    fits.Column(name = 'ERROR', format='D',array=result[2]),\n",
    "    fits.Column(name = 'INST', format='I',array=result[3])])\n",
    "\n",
    "hdulA = fits.HDUList([primary,hduA])\n",
    "hdulA.writeto(FILENAME,overwrite=True)\n",
    "\n",
    "hdulA.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a0080",
   "metadata": {},
   "source": [
    "# Read & plot FITS file to double check :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('./%s/%s_combined_x1d_FINAL.fits'%(STAR,STAR)) as hdul:\n",
    "    data = hdul[1].data\n",
    "    \n",
    "    hdul.close()\n",
    "\n",
    "fig,ax = plt.subplots(3,1,figsize=(7,7),tight_layout=True,sharex=True)\n",
    "spf.setup_axis(ax)\n",
    "ax[0].plot(data['WAVELENGTH'],data['FLUX'])\n",
    "ax[1].plot(data['WAVELENGTH'],data['FLUX']/data['ERROR'])\n",
    "ax[2].plot(data['WAVELENGTH'],data['INST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d31638",
   "metadata": {},
   "source": [
    "# Random debugging, testing, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3b9417",
   "metadata": {},
   "source": [
    "## Test Instrument binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34534bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wave = gratings['G140L'][0]\n",
    "test_flux = gratings['G140L'][1]\n",
    "test_inst = gratings['G140L'][3]\n",
    "\n",
    "test_inst[100:102] = INST_BITS['proxy']\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "plt.plot(test_wave,test_flux)\n",
    "plt.subplot(212,sharex=ax1)\n",
    "plt.plot(test_wave,test_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = combined_spectrum_nolines[0][-1] - combined_spectrum_nolines[0][0]\n",
    "\n",
    "test_flux_binned,flux_bins,_ = binned_statistic(x=combined_spectrum_nolines[0],\n",
    "                                                values=combined_spectrum_nolines[1],\n",
    "                                                bins=num_bins,statistic='mean')\n",
    "test_inst_binned,inst_bins,_ = binned_statistic(x=combined_spectrum_nolines[0],\n",
    "                                                values=combined_spectrum_nolines[3],\n",
    "                                                bins=num_bins,statistic=get_inst_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(211)\n",
    "plt.plot(flux_bins[0:-1],test_flux_binned)\n",
    "plt.subplot(212,sharex=ax1)\n",
    "plt.plot(inst_bins[0:-1],test_inst_binned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6f69b",
   "metadata": {},
   "source": [
    "## GJ 832 Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('./Proxy stars/GJ 832/hlsp_muscles_multi_multi_gj832_broadband_v22_var-res-sed.fits') as hdul:\n",
    "    plt.figure()\n",
    "    plt.semilogy(hdul[1].data['WAVELENGTH'],hdul[1].data['FLUX'])\n",
    "    \n",
    "    gjwave = hdul[1].data['WAVELENGTH']\n",
    "    gjflux = hdul[1].data['FLUX']\n",
    "    \n",
    "gj_832_apec = pd.read_csv('./GJ_832_apec.csv')\n",
    "#\n",
    "#plt.plot(h*c/gj_832_apec['energy'],gj_832_apec['model_flux']*erg*gj_832_apec['energy']**2/(h*c)*(9.35e-15/9.365e-10))\n",
    "#\n",
    "plt.figure()\n",
    "plt.plot(np.diff(gjwave[(gjwave > 20) & (gjwave < 100)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(combined_spectrum_nolines[0][0],combined_spectrum_nolines[0][-1],step=1)\n",
    "bin_ind = np.digitize(combined_spectrum_nolines[0],bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_bins = np.mean(combined_spectrum_nolines[1][[bin_ind==i] for i in bins],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3cc3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db223a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g140m_spec1d = Spectrum1D(spectral_axis=gratings['G140M'][0]*u.AA,\n",
    "                          flux=gratings['G140M'][1]*u.Unit('erg cm-2 s-1 AA-1'),\n",
    "                          uncertainty=StdDevUncertainty(gratings['G140M'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g140m_spec1d.spectral_axis,g140m_spec1d.flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(7,7),tight_layout=True)\n",
    "ax.tick_params(which='both',direction='in',top=True,right=True,length=7,width=1.5,labelsize=14)\n",
    "ax.tick_params(which='minor',length=4,width=1)\n",
    "ax.minorticks_on()\n",
    "ax.grid(which='both',alpha=0.5)\n",
    "\n",
    "ax.errorbar(x=x_ray_obs['energy'],\n",
    "           y=x_ray_obs['counts'],\n",
    "           xerr=x_ray_obs['bin_width'],\n",
    "           yerr=x_ray_obs['counts_err'],linestyle='',marker='.',markersize=3,label='L 98-59 XMM-Newton',zorder=2)\n",
    "ax.plot(APEC_model['energy'],APEC_model['model_flux'],zorder=1,lw=0.8,label='APEC')\n",
    "ax.set_xlabel('Energy [keV]',fontsize=14)\n",
    "ax.set_ylabel(r'counts s$^{-1}$ cm$^{-2}$ keV$^{-1}$',fontsize=14)\n",
    "ax.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cfd9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = './L-98-59/XMM/flare_analysis/F301/L-98-59_xray.fits'\n",
    "\n",
    "hdr = fits.Header()\n",
    "hdr['COMMENT'] = 'L 98-59 XMM-Newton spectrum'\n",
    "\n",
    "primary = fits.PrimaryHDU(header=hdr)\n",
    "\n",
    "hduA = fits.BinTableHDU.from_columns([\n",
    "    fits.Column(name = 'ENERGY',format='D',array=x_ray_obs['energy']),\n",
    "    fits.Column(name = 'BIN_WIDTH',format='D',array=x_ray_obs['bin_width']),\n",
    "    fits.Column(name = 'PHOTFLUX',format='D',array=x_ray_obs['counts']),\n",
    "    fits.Column(name = 'ERROR', format='D',array=x_ray_obs['counts_err'])])\n",
    "\n",
    "hdulA = fits.HDUList([primary,hduA])\n",
    "hdulA.writeto(FILENAME,overwrite=True)\n",
    "\n",
    "hdulA.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = './L-98-59/XMM/flare_analysis/F301/L-98-59_APEC.fits'\n",
    "\n",
    "hdr = fits.Header()\n",
    "hdr['COMMENT'] = 'L 98-59 APEC Model'\n",
    "\n",
    "primary = fits.PrimaryHDU(header=hdr)\n",
    "\n",
    "hduA = fits.BinTableHDU.from_columns([\n",
    "    fits.Column(name = 'ENERGY',format='D',array=APEC_model['energy']),\n",
    "    fits.Column(name = 'PHOTFLUX',format='D',array=APEC_model['model_flux'])])\n",
    "hdulA = fits.HDUList([primary,hduA])\n",
    "hdulA.writeto(FILENAME,overwrite=True)\n",
    "\n",
    "hdulA.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('./L-98-59/XMM/flare_analysis/F301/L-98-59_xray.fits') as hdul:\n",
    "    xray = hdul[1].data\n",
    "    \n",
    "    hdul.close()\n",
    "    \n",
    "with fits.open('./L-98-59/XMM/flare_analysis/F301/L-98-59_APEC.fits') as hdul:\n",
    "    apec = hdul[1].data\n",
    "    \n",
    "    hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ad66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(7,7),tight_layout=True)\n",
    "[x.set_linewidth(1.5) for x in ax.spines.values()]\n",
    "ax.tick_params(which='both',direction='in',top=True,right=True,length=7,width=1.5,labelsize=14)\n",
    "ax.tick_params(which='minor',length=4,width=1)\n",
    "ax.minorticks_on()\n",
    "ax.grid(which='both',alpha=0.2)\n",
    "\n",
    "ax.errorbar(x=xray['ENERGY'],\n",
    "           y=xray['PHOTFLUX']*1000,\n",
    "           xerr=xray['BIN_WIDTH'],\n",
    "           yerr=xray['ERROR']*1000,linestyle='',marker='.',markersize=4,elinewidth=2.,label='L 98-59 XMM-Newton',zorder=2,color='r')\n",
    "ax.plot(apec['ENERGY'],apec['PHOTFLUX']*1000,zorder=1,lw=0.8,label='APEC',c='w')\n",
    "ax.set_xlabel('Energy [keV]',fontsize=14)\n",
    "ax.set_ylabel(r'10$^{-3}$ counts s$^{-1}$ cm$^{-2}$ keV$^{-1}$',fontsize=14)\n",
    "ax.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12146706",
   "metadata": {},
   "outputs": [],
   "source": [
    "lya_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lya_data)):\n",
    "    print(lya_data['lya_intrinsic_low_1sig'][i],lya_data['lya_intrinsic_median'][i],lya_data['lya_intrinsic_high_1sig'][i])\n",
    "    print('Lower 1sig: ',lya_data['lya_intrinsic_median'][i]-lya_data['lya_intrinsic_low_1sig'][i])\n",
    "    print('Upper 1sig: ',lya_data['lya_intrinsic_high_1sig'][i]-lya_data['lya_intrinsic_median'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee20383",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#  Lya recon figure for paper #\n",
    "###############################\n",
    "\n",
    "W77A = 'C:/Users/pabe9855/Desktop/Directories/MEATS/data/WASP-77A/G140M/x1d_coadd.fits'\n",
    "\n",
    "with fits.open(W77A) as hdul:\n",
    "    W77A_wave = hdul[1].data['WAVELENGTH']\n",
    "    W77A_flux = hdul[1].data['FLUX']\n",
    "    \n",
    "W77Lya_dir = 'C:/Users/pabe9855/Desktop/Directories/MEATS/data/WASP-77A/lya_reconstruction/WASP-77A_lya_intrinsic_profile.csv'\n",
    "W77Lya = pd.read_csv(W77Lya_dir)\n",
    "\n",
    "W77Lya = np.array([W77Lya['wave'],W77Lya['flux']])\n",
    "\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6),tight_layout=True)\n",
    "for axis in ax:\n",
    "    [x.set_linewidth(1.5) for x in axis.spines.values()]\n",
    "    axis.tick_params(which='both',direction='in',top=True,right=True,length=7,width=1.5,labelsize=13)\n",
    "    axis.tick_params(which='minor',length=4,width=1.0)\n",
    "    axis.minorticks_on()\n",
    "    \n",
    "ax[0].set_ylabel(r'Flux Density [10$^{-14}$ erg  s$^{-1}$ cm$^{-2}$ Ã…$^{-1}$]',fontsize=15)\n",
    "ax[0].set_xlabel(r'Wavelength [Ã…]',fontsize=15)\n",
    "ax[0].step(gratings['G140M'][0],gratings['G140M'][1]*1e14,label='STIS G140M')\n",
    "ax[0].step(lya[0],lya[1]*1e14,label=r'L$\\alpha$ MCMC reconstruction')\n",
    "ax[0].legend(fontsize=12,loc='lower right')\n",
    "ax[0].set_title('HD 149026',fontsize=16)\n",
    "ax[0].set_xlim([1213.277,1218.190])\n",
    "ax[0].set_ylim([-0.910,1.940])\n",
    "\n",
    "ax[1].set_ylabel(r'Flux Density [10$^{-15}$ erg  s$^{-1}$ cm$^{-2}$ Ã…$^{-1}$]',fontsize=15)\n",
    "ax[1].set_xlabel(r'Wavelength [Ã…]',fontsize=15)\n",
    "ax[1].step(W77A_wave,W77A_flux*1e15,label='STIS G140M')\n",
    "ax[1].step(W77Lya[0],W77Lya[1]*1e15,label=r'L$\\alpha$ MgII estimation')\n",
    "ax[1].legend(fontsize=12,loc='lower right')\n",
    "ax[1].set_title('WASP-77A',fontsize=16)\n",
    "ax[1].set_xlim([1210.478,1220.614])\n",
    "ax[1].set_ylim([-3.279,6.316])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce943d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('./HD-149026/XMM/0763460301/data_prod/src_timefilt_lc.fits') as hdul:\n",
    "    data = hdul[1].data\n",
    "    hdul.close()\n",
    "    \n",
    "plt.plot(data['TIME'],data['RATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d01460",
   "metadata": {},
   "source": [
    "# Extinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dust_extinction\n",
    "from dust_extinction.averages import GCC09_MWAvg,I05_MWAvg\n",
    "\n",
    "Rv = 3.1\n",
    "Ev = 0.04\n",
    "Av = Rv*Ev\n",
    "print('Av=',Av)\n",
    "\n",
    "x=np.arange(913,7000,0.01)*u.AA\n",
    "\n",
    "ext_model = GCC09_MWAvg()\n",
    "ext_corr = ext_model.extinguish(x=x,Ebv=Ev)\n",
    "\n",
    "with fits.open('./WASP-77A/combined_spectrum/WASP-77A_x1d_native_res.fits') as hdul:\n",
    "    data = hdul[1].data\n",
    "    hdul.close()\n",
    "    \n",
    "\n",
    "# interpolate ext_curve onto wavelength grid\n",
    "reg = (data['WAVELENGTH'] > x[0]*1/u.AA) & (data['WAVELENGTH'] < x[-1]*1/u.AA)\n",
    "ext_corr_interp = np.interp(x=data['WAVELENGTH'][reg]*u.AA,xp=x,fp=ext_corr)\n",
    "\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "gs = fig.add_gridspec(2,1,height_ratios=(1,3),wspace=0.05,hspace=0.05)\n",
    "ax_top = fig.add_subplot(gs[0])\n",
    "ax_bot = fig.add_subplot(gs[1],sharex=ax_top)\n",
    "spf.setup_axis(ax_top)\n",
    "spf.setup_axis(ax_bot)\n",
    "ax_top.plot(data['WAVELENGTH'][reg],1/ext_corr_interp,label='GCC09')\n",
    "ax_top.plot()\n",
    "ax_top.set_ylabel(r'Correction factor',fontsize=14)\n",
    "ax_top.tick_params(labelbottom=False)\n",
    "\n",
    "ax_bot.semilogy(data['WAVELENGTH'][reg],data['FLUX'][reg]*1e14,label='reddened')\n",
    "ax_bot.semilogy(data['WAVELENGTH'][reg],data['FLUX'][reg]/ext_corr_interp*1e14,label='unreddened')\n",
    "ax_bot.set_xlabel('Wavelength [Ã…]',fontsize=14)\n",
    "ax_bot.set_ylabel('Flux dens [0$^{-14}$ erg s$^{-1}$ cm$^{-2}$ Ã…$^{-1}$]',fontsize=14)\n",
    "ax_bot.legend(fontsize=14)\n",
    "\n",
    "fig.suptitle('WASP-77A Unreddened (d=105pc, R_v = 3.1, E_v = 0.04, A_v=%0.3f)'%(Av),fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dust_extinction\n",
    "from dust_extinction.averages import GCC09_MWAvg,I05_MWAvg\n",
    "\n",
    "Rv = 3.1\n",
    "Ev = -0.43\n",
    "Av = Rv*Ev\n",
    "print('Av=',Av)\n",
    "\n",
    "x=np.arange(913,7000,0.01)*u.AA\n",
    "\n",
    "ext_model = GCC09_MWAvg()\n",
    "ext_corr = ext_model.extinguish(x=x,Av=0.1)\n",
    "\n",
    "with fits.open('./WASP-127/combined_spectrum/WASP-127_x1d_native_res.fits') as hdul:\n",
    "    data = hdul[1].data\n",
    "    hdul.close()\n",
    "    \n",
    "\n",
    "# interpolate ext_curve onto wavelength grid\n",
    "reg = (data['WAVELENGTH'] > x[0]*1/u.AA) & (data['WAVELENGTH'] < x[-1]*1/u.AA)\n",
    "ext_corr_interp = np.interp(x=data['WAVELENGTH'][reg]*u.AA,xp=x,fp=ext_corr)\n",
    "\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "gs = fig.add_gridspec(2,1,height_ratios=(1,3),wspace=0.05,hspace=0.05)\n",
    "ax_top = fig.add_subplot(gs[0])\n",
    "ax_bot = fig.add_subplot(gs[1],sharex=ax_top)\n",
    "spf.setup_axis(ax_top)\n",
    "spf.setup_axis(ax_bot)\n",
    "ax_top.plot(data['WAVELENGTH'][reg],1/ext_corr_interp,label='GCC09')\n",
    "ax_top.plot()\n",
    "ax_top.set_ylabel(r'Correction factor',fontsize=14)\n",
    "ax_top.tick_params(labelbottom=False)\n",
    "\n",
    "ax_bot.semilogy(data['WAVELENGTH'][reg],data['FLUX'][reg]*1e14,label='reddened')\n",
    "ax_bot.semilogy(data['WAVELENGTH'][reg],data['FLUX'][reg]/ext_corr_interp*1e14,label='unreddened')\n",
    "ax_bot.set_xlabel('Wavelength [Ã…]',fontsize=14)\n",
    "ax_bot.set_ylabel('Flux dens [0$^{-14}$ erg s$^{-1}$ cm$^{-2}$ Ã…$^{-1}$]',fontsize=14)\n",
    "ax_bot.legend(fontsize=14)\n",
    "\n",
    "fig.suptitle('WASP-77A Unreddened (d=105pc, R_v = 3.1, E_v = %0.3f, A_v=%0.3f)'%(Ev,Av),fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774c45c",
   "metadata": {},
   "source": [
    "# Test Ly$\\alpha$ flux along wing drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6763ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,tight_layout=True)\n",
    "spf.setup_axis(ax)\n",
    "ax.semilogy(data['WAVELENGTH'],data['FLUX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Click points for spline 1')\n",
    "points_for_spline1 = np.array(fig.ginput(n=-1,timeout=-1))\n",
    "print('Click points for spline 2')\n",
    "points_for_spline2 = np.array(fig.ginput(n=-1,timeout=-1))\n",
    "\n",
    "spline_lam1 = points_for_spline1[:,0]\n",
    "spline_flux1 = points_for_spline1[:,1]\n",
    "spline_lam2 = points_for_spline2[:,0]\n",
    "spline_flux2 = points_for_spline2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_array1 = np.linspace(spline_lam1[0],spline_lam1[-1],1000)\n",
    "lam_array2 = np.linspace(spline_lam2[0],spline_lam2[-1],1000)\n",
    "\n",
    "spline1 = CubicSpline(spline_lam1,spline_flux1)\n",
    "spline2 = CubicSpline(spline_lam2,spline_flux2)\n",
    "\n",
    "ax.plot(lam_array1,spline1(lam_array1))\n",
    "ax.plot(lam_array2,spline2(lam_array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_reg1 = (data['WAVELENGTH'] >= lam_array1[0]) & (data['WAVELENGTH'] <= lam_array1[-1])\n",
    "wave_reg2 = (data['WAVELENGTH'] >= lam_array2[0]) & (data['WAVELENGTH'] <= lam_array2[-1])\n",
    "missing_flux = (np.trapz(x=lam_array1,y=spline1(lam_array1))+np.trapz(x=lam_array2,y=spline2(lam_array2))-\n",
    "                np.trapz(x=data['WAVELENGTH'][wave_reg1],y=data['FLUX'][wave_reg1])+\n",
    "                np.trapz(x=data['WAVELENGTH'][wave_reg2],y=data['FLUX'][wave_reg2]))\n",
    "\n",
    "tot_reg = (data['WAVELENGTH'] >= lam_array1[0]) & (data['WAVELENGTH'] <= lam_array2[-1])\n",
    "\n",
    "print(missing_flux)\n",
    "tot_flux = np.trapz(x=data['WAVELENGTH'][tot_reg],y=data['FLUX'][tot_reg])\n",
    "print(tot_flux)\n",
    "print('------Flux ratio------')\n",
    "print(missing_flux/tot_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca2a90",
   "metadata": {},
   "source": [
    "# Get solar FWHM & convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940912d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_dat = readsav('./Proxy stars/Solar/solar-data.idlsav')\n",
    "solar_wave = solar_dat['wave']*10\n",
    "solar_flux = solar_dat['flux']*100\n",
    "plt.figure()\n",
    "plt.plot(solar_wave,solar_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2da57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x,a,mu,sig,o):\n",
    "    return a*np.exp(-1/2*((x-mu)/sig)**2)+o\n",
    "\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9172517",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Click continuum, peak, half-max')\n",
    "line_points = plt.ginput(n=-1,timeout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9148bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont1 = 606.\n",
    "cont2 = 614.\n",
    "line_points = np.asarray(line_points)\n",
    "reg = (solar_wave > cont1) & (solar_wave < cont2)\n",
    "\n",
    "a = line_points[1,1]\n",
    "o = line_points[0,1]\n",
    "mu = line_points[1,0]\n",
    "sig = np.abs(line_points[2,0]-line_points[1,0])/2.355\n",
    "\n",
    "gauss_fit,cov = curve_fit(f=gaussian,xdata=solar_wave[reg],ydata=solar_flux[reg],p0=[a,mu,sig,o])\n",
    "print(gauss_fit)\n",
    "print('FWHM = %0.4f'%(2.355*gauss_fit[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fa632",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.linspace(cont1,cont2,1000)\n",
    "plt.plot(x_new,gaussian(x_new,gauss_fit[0],gauss_fit[1],gauss_fit[2],gauss_fit[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a63997",
   "metadata": {},
   "source": [
    "#### Solar FWHM based on a few points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c97c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fwhm=np.average((1.8,1.13,1.59,1.3,1.05,1.21,1.50))\n",
    "print(avg_fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_l98 = convolve_fft(data['FLUX'],Gaussian1DKernel(stddev=1.3685714/2.355))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,tight_layout=True)\n",
    "spf.setup_axis(ax,xlabel='Wavelength [Ã…]',ylabel=r'Flux density [10$^{-14}$ erg s$^{-1}$ cm$^{-2}$ Ã…$^{-1}$]')\n",
    "ax.plot(data['WAVELENGTH'],convolved_l98*1e14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf907fe",
   "metadata": {},
   "source": [
    "# FUV / NUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuv_reg = (data['WAVELENGTH'] > 1350) & (data['WAVELENGTH'] < 1780)\n",
    "\n",
    "nuv_reg = (data['WAVELENGTH'] > 1770) & (data['WAVELENGTH'] < 2730)\n",
    "\n",
    "fuv_wave = data['WAVELENGTH'][fuv_reg]\n",
    "fuv_flux = data['FLUX'][fuv_reg]\n",
    "fuv_err = data['ERROR'][fuv_reg]\n",
    "nuv_wave = data['WAVELENGTH'][nuv_reg]\n",
    "nuv_flux = data['FLUX'][nuv_reg]\n",
    "nuv_err = data['ERROR'][nuv_reg]\n",
    "\n",
    "trials = 10000\n",
    "fuv_flux_trials = np.zeros(trials)\n",
    "nuv_flux_trials = np.zeros(trials)\n",
    "\n",
    "for i in range(trials):\n",
    "    fuv_temp_flux_array = np.random.normal(loc=fuv_flux,scale=fuv_err)\n",
    "    fuv_flux_trials[i] = np.trapz(x=fuv_wave,y=fuv_temp_flux_array)\n",
    "    \n",
    "    nuv_temp_flux_array = np.random.normal(loc=nuv_flux,scale=nuv_err)\n",
    "    nuv_flux_trials[i] = np.trapz(x=nuv_wave,y=nuv_temp_flux_array)\n",
    "    \n",
    "fuv = np.mean(fuv_flux_trials)\n",
    "fuv_err = np.std(fuv_flux_trials)\n",
    "\n",
    "nuv = np.mean(nuv_flux_trials)\n",
    "nuv_err = np.std(nuv_flux_trials)\n",
    "\n",
    "print('%0.4e +/- %0.4e'%(fuv/nuv,fuv/nuv*np.sqrt((fuv_err/fuv)**2+(nuv_err/nuv)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383400c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
